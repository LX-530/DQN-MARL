# ğŸ¤– DQNæ¨¡å‹å¯¼å…¥å’Œä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»å¦‚ä½•åŠ è½½å’Œä½¿ç”¨è®­ç»ƒå¥½çš„DQNç–æ•£æ¨¡å‹ã€‚

## ğŸ—‚ï¸ æ¨¡å‹æ–‡ä»¶è¯´æ˜

è®­ç»ƒå®Œæˆåï¼Œåœ¨ `dqn_results/` ç›®å½•ä¸‹ä¼šç”Ÿæˆä»¥ä¸‹æ¨¡å‹æ–‡ä»¶ï¼š

| æ–‡ä»¶å | è¯´æ˜ | ä½¿ç”¨åœºæ™¯ |
|--------|------|----------|
| `best_model.pth` | æ€»ä½“æœ€ä½³æ¨¡å‹ | ç»¼åˆæ€§èƒ½æœ€å¥½çš„æ¨¡å‹ |
| `best_evacuation_model.pth` | ç–æ•£æ•ˆæœæœ€ä½³æ¨¡å‹ | ä¸“é—¨é’ˆå¯¹ç–æ•£ç‡ä¼˜åŒ–çš„æ¨¡å‹ |
| `model_episode_X.pth` | ç‰¹å®šå›åˆæ¨¡å‹ | è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜çš„æ£€æŸ¥ç‚¹ |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1ï¼šä½¿ç”¨å®Œæ•´çš„æ¨¡å‹åŠ è½½å™¨

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd CA-dqn1/Louvre_Evacuation

# è¿è¡Œæ¨¡å‹åŠ è½½å™¨
python load_and_use_model.py
```

### æ–¹æ³•2ï¼šä½¿ç”¨ç°æœ‰çš„è¯„ä¼°è„šæœ¬

```bash
# è¿è¡Œæ¨¡å‹è¯„ä¼°
python evaluate_model.py
```

## ğŸ’» ä»£ç ç¤ºä¾‹

### åŸºæœ¬æ¨¡å‹åŠ è½½

```python
import torch
from agents.dqn_agent import DQNAgent
from envs.evacuation_env import EvacuationEnv

# 1. åˆ›å»ºç¯å¢ƒ
env = EvacuationEnv(
    width=36,
    height=30,
    num_people=150,
    fire_zones=[[18, 14], [19, 15], [20, 16]],
    exit_location=[36, 15]
)

# 2. åˆ›å»ºæ™ºèƒ½ä½“
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
agent = DQNAgent(
    state_size=env.state_size,
    action_size=env.action_size,
    device=device,
    config={
        'learning_rate': 0.001,
        'gamma': 0.99,
        'epsilon': 0.0,  # æ¨ç†æ—¶ä¸ä½¿ç”¨æ¢ç´¢
        'hidden_size': 256
    }
)

# 3. åŠ è½½æ¨¡å‹
model_path = 'dqn_results/best_model.pth'
agent.load(model_path)
agent.epsilon = 0.0  # ç¡®ä¿æ¨ç†æ—¶ä¸æ¢ç´¢

print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
```

### è¿è¡Œå•ä¸ªå›åˆ

```python
# é‡ç½®ç¯å¢ƒ
state = env.reset()
total_reward = 0
step_count = 0
done = False

print("ğŸƒ å¼€å§‹ç–æ•£æ¨¡æ‹Ÿ...")

while not done:
    # æ™ºèƒ½ä½“é€‰æ‹©åŠ¨ä½œ
    action = agent.act(state)
    
    # æ‰§è¡ŒåŠ¨ä½œ
    next_state, reward, done, info = env.step(action)
    
    # æ›´æ–°çŠ¶æ€
    state = next_state
    total_reward += reward
    step_count += 1
    
    # æ‰“å°è¿›åº¦
    if step_count % 10 == 0:
        evacuation_rate = info.get('evacuation_rate', 0.0)
        death_rate = info.get('death_rate', 0.0)
        print(f"æ­¥éª¤ {step_count}: ç–æ•£ç‡={evacuation_rate:.1%}, æ­»äº¡ç‡={death_rate:.1%}")

# è¾“å‡ºæœ€ç»ˆç»“æœ
print(f"\nğŸ“Š ç–æ•£å®Œæˆ!")
print(f"æ€»æ­¥æ•°: {step_count}")
print(f"æ€»å¥–åŠ±: {total_reward:.2f}")
print(f"ç–æ•£ç‡: {info.get('evacuation_rate', 0.0):.1%}")
print(f"æ­»äº¡ç‡: {info.get('death_rate', 0.0):.1%}")
```

### æ‰¹é‡è¯„ä¼°

```python
def evaluate_model(agent, env, num_episodes=10):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    results = []
    
    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0
        done = False
        
        while not done:
            action = agent.act(state)
            next_state, reward, done, info = env.step(action)
            state = next_state
            total_reward += reward
        
        results.append({
            'episode': episode + 1,
            'reward': total_reward,
            'evacuation_rate': info.get('evacuation_rate', 0.0),
            'death_rate': info.get('death_rate', 0.0)
        })
        
        print(f"å›åˆ {episode + 1}: å¥–åŠ±={total_reward:.2f}, "
              f"ç–æ•£ç‡={info['evacuation_rate']:.1%}")
    
    return results

# è¿è¡Œè¯„ä¼°
results = evaluate_model(agent, env, num_episodes=10)

# è®¡ç®—å¹³å‡æ€§èƒ½
avg_reward = sum(r['reward'] for r in results) / len(results)
avg_evacuation = sum(r['evacuation_rate'] for r in results) / len(results)
avg_death = sum(r['death_rate'] for r in results) / len(results)

print(f"\nğŸ“ˆ å¹³å‡æ€§èƒ½:")
print(f"å¹³å‡å¥–åŠ±: {avg_reward:.2f}")
print(f"å¹³å‡ç–æ•£ç‡: {avg_evacuation:.1%}")
print(f"å¹³å‡æ­»äº¡ç‡: {avg_death:.1%}")
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰ç¯å¢ƒå‚æ•°

```python
# åˆ›å»ºè‡ªå®šä¹‰ç¯å¢ƒ
custom_env = EvacuationEnv(
    width=40,           # è‡ªå®šä¹‰åœ°å›¾å®½åº¦
    height=35,          # è‡ªå®šä¹‰åœ°å›¾é«˜åº¦
    num_people=200,     # è‡ªå®šä¹‰äººå‘˜æ•°é‡
    fire_zones=[[20, 15], [21, 16]],  # è‡ªå®šä¹‰ç«æºä½ç½®
    exit_location=[40, 17]  # è‡ªå®šä¹‰å‡ºå£ä½ç½®
)

# æ³¨æ„ï¼šå¦‚æœç¯å¢ƒå‚æ•°ä¸è®­ç»ƒæ—¶ä¸åŒï¼Œå¯èƒ½å½±å“æ¨¡å‹æ€§èƒ½
```

### æ¨¡å‹æ€§èƒ½åˆ†æ

```python
import matplotlib.pyplot as plt
import numpy as np

def analyze_performance(results):
    """åˆ†ææ¨¡å‹æ€§èƒ½"""
    rewards = [r['reward'] for r in results]
    evacuation_rates = [r['evacuation_rate'] for r in results]
    death_rates = [r['death_rate'] for r in results]
    
    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # å¥–åŠ±åˆ†å¸ƒ
    axes[0].hist(rewards, bins=10, alpha=0.7, color='blue')
    axes[0].set_title('å¥–åŠ±åˆ†å¸ƒ')
    axes[0].set_xlabel('å¥–åŠ±')
    axes[0].set_ylabel('é¢‘æ¬¡')
    
    # ç–æ•£ç‡åˆ†å¸ƒ
    axes[1].hist([r*100 for r in evacuation_rates], bins=10, alpha=0.7, color='green')
    axes[1].set_title('ç–æ•£ç‡åˆ†å¸ƒ')
    axes[1].set_xlabel('ç–æ•£ç‡ (%)')
    axes[1].set_ylabel('é¢‘æ¬¡')
    
    # æ­»äº¡ç‡åˆ†å¸ƒ
    axes[2].hist([r*100 for r in death_rates], bins=10, alpha=0.7, color='red')
    axes[2].set_title('æ­»äº¡ç‡åˆ†å¸ƒ')
    axes[2].set_xlabel('æ­»äº¡ç‡ (%)')
    axes[2].set_ylabel('é¢‘æ¬¡')
    
    plt.tight_layout()
    plt.savefig('model_performance_analysis.png', dpi=300)
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹
analyze_performance(results)
```

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### 1. å•æ¬¡ç–æ•£æ¨¡æ‹Ÿ
é€‚ç”¨äºï¼š
- éªŒè¯æ¨¡å‹æ•ˆæœ
- è§‚å¯Ÿç–æ•£è¿‡ç¨‹
- ç”Ÿæˆå¯è§†åŒ–ç»“æœ

### 2. æ‰¹é‡æ€§èƒ½è¯„ä¼°
é€‚ç”¨äºï¼š
- æ¨¡å‹æ€§èƒ½ç»Ÿè®¡
- ä¸åŒæ¨¡å‹å¯¹æ¯”
- ç¨³å®šæ€§æµ‹è¯•

### 3. å‚æ•°æ•æ„Ÿæ€§åˆ†æ
é€‚ç”¨äºï¼š
- æµ‹è¯•ä¸åŒç¯å¢ƒå‚æ•°
- è¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›
- å¯»æ‰¾æœ€ä¼˜é…ç½®

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ¨¡å‹å…¼å®¹æ€§
- ç¡®ä¿ç¯å¢ƒå‚æ•°ä¸è®­ç»ƒæ—¶ä¸€è‡´
- æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´
- éªŒè¯PyTorchç‰ˆæœ¬å…¼å®¹æ€§

### 2. æ€§èƒ½è€ƒè™‘
- GPUåŠ é€Ÿæ¨ç†é€Ÿåº¦æ›´å¿«
- æ‰¹é‡è¯„ä¼°æ—¶æ³¨æ„å†…å­˜ä½¿ç”¨
- å¤§è§„æ¨¡ç¯å¢ƒå¯èƒ½éœ€è¦æ›´å¤šè®¡ç®—èµ„æº

### 3. ç»“æœè§£é‡Š
- æ¨¡å‹æ€§èƒ½å¯èƒ½å› éšæœºæ€§è€Œæœ‰æ³¢åŠ¨
- å¤šæ¬¡è¿è¡Œå–å¹³å‡å€¼æ›´å¯é 
- å…³æ³¨ç–æ•£ç‡å’Œæ­»äº¡ç‡çš„å¹³è¡¡

## ğŸ› å¸¸è§é—®é¢˜

### Q: æ¨¡å‹åŠ è½½å¤±è´¥
**A:** æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
- æ¨¡å‹æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
- æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´ï¼ˆæœªæŸåï¼‰
- PyTorchç‰ˆæœ¬æ˜¯å¦å…¼å®¹
- è®¾å¤‡ï¼ˆCPU/GPUï¼‰æ˜¯å¦åŒ¹é…

### Q: æ¨ç†ç»“æœä¸ç†æƒ³
**A:** å¯èƒ½çš„åŸå› ï¼š
- ç¯å¢ƒå‚æ•°ä¸è®­ç»ƒæ—¶ä¸åŒ¹é…
- æ¨¡å‹è®­ç»ƒä¸å……åˆ†
- æµ‹è¯•ç¯å¢ƒè¿‡äºå¤æ‚
- éšæœºç§å­å½±å“

### Q: å†…å­˜ä¸è¶³
**A:** è§£å†³æ–¹æ¡ˆï¼š
- å‡å°‘æ‰¹é‡è¯„ä¼°çš„å›åˆæ•°
- ä½¿ç”¨CPUè€ŒéGPU
- å‡å°‘ç¯å¢ƒä¸­çš„äººå‘˜æ•°é‡
- å…³é—­ä¸å¿…è¦çš„å¯è§†åŒ–

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å®Œæ•´
2. ä¾èµ–åº“æ˜¯å¦æ­£ç¡®å®‰è£…
3. ç¯å¢ƒé…ç½®æ˜¯å¦åŒ¹é…
4. æ—¥å¿—è¾“å‡ºä¸­çš„é”™è¯¯ä¿¡æ¯

## ğŸ”— ç›¸å…³æ–‡ä»¶

- `load_and_use_model.py` - å®Œæ•´çš„æ¨¡å‹åŠ è½½å™¨
- `evaluate_model.py` - æ¨¡å‹è¯„ä¼°è„šæœ¬
- `agents/dqn_agent.py` - DQNæ™ºèƒ½ä½“å®ç°
- `envs/evacuation_env.py` - ç–æ•£ç¯å¢ƒå®ç°
- `configs/dqn.yaml` - é…ç½®æ–‡ä»¶

---

âœ… **ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼** å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒä»£ç æ³¨é‡Šæˆ–è”ç³»å¼€å‘è€…ã€‚ 